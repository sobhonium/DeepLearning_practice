{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4562e613-d467-428e-ac70-434f8f76d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 2023\n",
    "# A walkthrough for batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b2b0e-533a-46c5-8eff-202334829c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b7f42bac-266c-4e68-b02c-81a47cedc271",
   "metadata": {},
   "source": [
    "Batch Norm is a normalization technique done between the layers of a Neural Network instead of in the raw data. It is done along mini-batches instead of the full data set. It serves to speed up training and use higher learning rates, making learning easie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8e87f-4f59-4752-929d-0990a73d5c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "0e6b82b3-cab1-45e6-807b-81bff034c0bc",
   "metadata": {},
   "source": [
    "In the following image, we can see a regular feed-forward Neural Network: x_i are the inputs, z the output of the neurons, a the output of the activation functions, and y the output of the network [1]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bddc67-2777-4eee-8e40-425ab0a8076f",
   "metadata": {},
   "source": [
    "![image](batch.png)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a686fd87-8b27-444f-ac8d-43eed35d486f",
   "metadata": {},
   "source": [
    "Batch Norm – in the image represented with a red line – is applied to the neurons’ output just before applying the activation function. Usually, a neuron without Batch Norm would be computed as follows [1]:\n",
    "z = g(x,w) + b, a = f(z), \n",
    "where z is the input of activation function f.\n",
    "\n",
    "and with batch normalization:\n",
    "\n",
    "z = g(x,w), z_new = alpha*(z-mu)/s +  beta \n",
    "and these alpha and beta are sometimes learnable or not (based on the programmer's interests). Sometimes in somepapers even mu and s are considered trainables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "13dfab24-e155-4e64-9652-61676b7b2ef1",
   "metadata": {},
   "source": [
    "So, The following is showing where you can put these normalization layers\n",
    "in neural network (pesudo in here not complete)\n",
    "\n",
    "nn.Sequential(\n",
    "            nn.Linear(...),\n",
    "            nn.BatchNorm(...),\n",
    "            nn.activationfunction(...),\n",
    "\n",
    "            nn.Linear(....),\n",
    "            nn.BatchNorm(...),\n",
    "            nn.activationfunction(...),\n",
    "\n",
    "            nn.Linear(....),\n",
    "            nn.activationfunction(...),    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e142a2c-2dfd-47c4-9aaf-d16ba7770762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is important here is that the input and output of this layer\n",
    "# is always of the same dimension. if you give it n n*n it gives you\n",
    "# an n*n output which is normalized.\n",
    "\n",
    "# I suggest you whatch [2] and [3] first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352a2f1a-0aa5-4b70-9f98-971edfd5afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7411736f-92a1-450b-84cb-ad94897b31fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b4a6bf-2aaa-4e8e-bbf4-42e521bdf1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6728, 0.8347],\n",
       "          [0.5499, 0.0040]],\n",
       "\n",
       "         [[0.8692, 0.8842],\n",
       "          [0.1897, 0.7183]]],\n",
       "\n",
       "\n",
       "        [[[0.0265, 0.7271],\n",
       "          [0.7613, 0.5915]],\n",
       "\n",
       "         [[0.1974, 0.0166],\n",
       "          [0.1354, 0.7594]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_n   = 2\n",
    "channel_n  = 2\n",
    "img_width  = 2\n",
    "img_height = 2\n",
    "img = torch.rand((sample_n, channel_n, img_width, img_height))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97be923-19c6-42b1-abfd-e33596dc4146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade456ca-5b70-4aa4-8aeb-c23bedb29a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e3fd7e7-3124-4d6d-8746-4190dbf0d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features here in BatchNormalization referes to num channels.\n",
    "# in other normalizations it means num of smaples in batch, etc.\n",
    "bn = torch.nn.BatchNorm2d(num_features=2, momentum=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27425187-5cee-4fff-897d-07701115ef19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4995,  1.0321],\n",
       "          [ 0.0950, -1.7004]],\n",
       "\n",
       "         [[ 1.1568,  1.2002],\n",
       "          [-0.8185,  0.7181]]],\n",
       "\n",
       "\n",
       "        [[[-1.6266,  0.6780],\n",
       "          [ 0.7904,  0.2320]],\n",
       "\n",
       "         [[-0.7961, -1.3217],\n",
       "          [-0.9762,  0.8375]]]], grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd20a10d-3523-4f89-987e-a6e2aa1947bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization is done 'accross samples'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0844c743-23e2-4a27-ad16-f1de5ff8dec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([1., 1.])),\n",
       "             ('bias', tensor([0., 0.])),\n",
       "             ('running_mean', tensor([0.5210, 0.4713])),\n",
       "             ('running_var', tensor([0.1056, 0.1352])),\n",
       "             ('num_batches_tracked', tensor(1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d1e58-9086-435a-a6ad-4047f5abe6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b385fbc2-eaf4-415b-be3f-29d74ce85860",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n   = 100\n",
    "channel_n  = 3\n",
    "img_width  = 28\n",
    "img_height = 28\n",
    "img = torch.rand((sample_n, channel_n, img_width, img_height))\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebda071-5fa6-4cd6-a934-c871585ae2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f7b8e95-3d89-4840-8a52-888f3fd71089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b66fbbe5-b984-4025-b900-bb4c98e13a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=channel_n, \n",
    "                          out_channels=16, \n",
    "                          kernel_size=(3, 3), padding=1 ),\n",
    "    \n",
    "                \n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.BatchNorm2d(16),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5566f70b-6d68-4091-857c-aa188fa0bcb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 14, 14])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cb967-9885-4fa0-b549-2f326808adcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72de0574-49f1-4e0a-a493-cf7da1d01a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9bf14f9-4380-4db5-9a0b-a5715e3abf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=channel_n, \n",
    "                          out_channels=16, \n",
    "                          kernel_size=(3, 3), padding=1 ),\n",
    "    \n",
    "                \n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.BatchNorm2d(16),\n",
    "                \n",
    "                nn.Conv2d(in_channels=16, \n",
    "                          out_channels=8, \n",
    "                          kernel_size=(3, 3), padding=1 ),\n",
    "    \n",
    "                \n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "733ce970-971e-4c57-a961-226155771721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 8, 7, 7])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4c325-7c8e-4265-8cd3-391ff71c1c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "925b66e3-bae6-4126-9238-0799752b8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=channel_n, \n",
    "                          out_channels=16, \n",
    "                          kernel_size=(3, 3), padding=1 ),\n",
    "    \n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16*28*28,24),\n",
    "                \n",
    "                nn.BatchNorm1d(24),\n",
    "                nn.ReLU()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "257ed47e-53a7-42b2-ad35-89782dc2ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at 16 and 24  in the top cell... It gives you\n",
    "# the intuition on how to set batch normalization inputs.\n",
    "# also becareful about the second batch layer, i.e.\n",
    "# BatchNorm1d instead of 2d. Cos we flattend that earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3a16f3f-8294-413d-9acc-2d81b755caf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 24])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9de15-f706-42e1-9d6e-c4090974744e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92d11133-d5b4-4fb4-a8de-1f7765890c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's been said that in real application momentum is chosen small like 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45c2200b-2ef1-4c40-998c-d9b729234c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=channel_n, \n",
    "                          out_channels=16, \n",
    "                          kernel_size=(3, 3), padding=1 ),\n",
    "\n",
    "                nn.BatchNorm2d(16, momentum=0.1),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7f60e40-6923-411a-b522-dc14d0d46a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 16, 28, 28])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27f3b1-042e-4939-a665-b89d3054fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad742a8-0802-4138-8dfe-61f9b8929b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e666811-820c-4b0a-897a-a663f1739bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# about the learnable params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b3301945-a939-4db0-89f5-e2c0a571a051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "nn.BatchNorm2d(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0e9d282-a137-4a93-8acb-5999af6355e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without Learnable Parameters\n",
    "nn.BatchNorm2d(100, affine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4ebd25e8-141d-4b2f-a118-e669b5fc9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: never forget to use net.eval() when ever you want to avoid some randomness\n",
    "# in the test or wherever you need that.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf361c-2529-40a6-bda2-fcdd218f1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are also groupnormalization, localnormalizationa and so forth."
   ]
  },
  {
   "cell_type": "raw",
   "id": "180d42de",
   "metadata": {},
   "source": [
    "You add the batch normalization layer before calling the activation function, so it always goes layer > batch norm > activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf8c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b6370ef8-549e-45e5-acbf-7171171e2e91",
   "metadata": {},
   "source": [
    "# Resources\n",
    "[1] https://www.baeldung.com/cs/batch-normalization-cnn\n",
    "[2] https://www.youtube.com/watch?v=1JmZ5idFcVI\n",
    "[3] https://www.youtube.com/watch?v=bCQ2cNhUWQ8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9469afc-be07-457f-a18b-df46d61a8764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd9ff6-5a35-43a9-b780-515f010d2924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12395e0-2f75-4b29-befd-0ce7e32f4567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

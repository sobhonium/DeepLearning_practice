{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d76749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding autoencoders via a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc61f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7df0b9a",
   "metadata": {},
   "source": [
    "## generate the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e07250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sobhan/miniconda3/envs/ml-dl/lib/python3.9/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d15117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I feel that there should be a relationship between columns in dataset.  not just random. Let's see if I'm right?\n",
    "## Comment: after figuring this in my mind, I realized it is always true to have a realtionship between features\n",
    "## in simple words, yeah they must have a relationship...!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f028793",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_col_random = torch.rand(10,1) # producing a random column\n",
    "features = torch.cat((first_col_random, 2*first_col_random), 1) # that is how a relationship between cols \n",
    "# are introduced here in my example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bafac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, I want to have more columns. each colmn is multiplied from first column\n",
    "first_col_random = torch.rand(1000,1) \n",
    "features = first_col_random # initial values for the fist col\n",
    "for i in range(2,5):\n",
    "    features = torch.cat((features, i*first_col_random), 1) # creation of other colmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ff1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364fdf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8835, 1.7670, 2.6504, 3.5339],\n",
       "        [0.5175, 1.0349, 1.5524, 2.0698],\n",
       "        [0.1425, 0.2851, 0.4276, 0.5702],\n",
       "        ...,\n",
       "        [0.9415, 1.8829, 2.8244, 3.7658],\n",
       "        [0.9987, 1.9974, 2.9961, 3.9948],\n",
       "        [0.2838, 0.5676, 0.8514, 1.1352]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see? they are multipied from the first col\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8ca338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_col_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fedbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a29bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2845a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in auto encoder we want a reperesentation of our data. The best representation here is the one\n",
    "# shows that colmns are multiplied from the first one (abvious). But this one seems like to be \n",
    "# an unsupervised learning. But no. Let's think differently. We want a representation x_ of our data x\n",
    "# so, I guess now it is a supervised learning. We only need to define ground truth as y = x and\n",
    "# come up with wieghts and biases (through training) to best fit this.\n",
    "\n",
    "# based on the explanation above, let's figure this out:\n",
    "labels = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100f8b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 4]), torch.Size([1000, 4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae333ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.8835, 1.7670, 2.6504, 3.5339]),\n",
       " tensor([0.8835, 1.7670, 2.6504, 3.5339]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cd045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30693f40",
   "metadata": {},
   "source": [
    "## Reading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29caf6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a4a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True): #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2e8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c1a5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f560c505760>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e37aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2952, 0.5904, 0.8856, 1.1808],\n",
       "         [0.8962, 1.7925, 2.6887, 3.5849],\n",
       "         [0.1158, 0.2316, 0.3474, 0.4633],\n",
       "         [0.2953, 0.5906, 0.8858, 1.1811],\n",
       "         [0.8624, 1.7248, 2.5871, 3.4495],\n",
       "         [0.4134, 0.8268, 1.2402, 1.6536],\n",
       "         [0.9247, 1.8494, 2.7742, 3.6989],\n",
       "         [0.3546, 0.7092, 1.0638, 1.4183],\n",
       "         [0.2100, 0.4199, 0.6299, 0.8398],\n",
       "         [0.3952, 0.7904, 1.1856, 1.5808]]),\n",
       " tensor([[0.2952, 0.5904, 0.8856, 1.1808],\n",
       "         [0.8962, 1.7925, 2.6887, 3.5849],\n",
       "         [0.1158, 0.2316, 0.3474, 0.4633],\n",
       "         [0.2953, 0.5906, 0.8858, 1.1811],\n",
       "         [0.8624, 1.7248, 2.5871, 3.4495],\n",
       "         [0.4134, 0.8268, 1.2402, 1.6536],\n",
       "         [0.9247, 1.8494, 2.7742, 3.6989],\n",
       "         [0.3546, 0.7092, 1.0638, 1.4183],\n",
       "         [0.2100, 0.4199, 0.6299, 0.8398],\n",
       "         [0.3952, 0.7904, 1.1856, 1.5808]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is import to use iterator for that\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee07d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0a65df7",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff8c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6de822be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bottleneck here is only of dim 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a40c2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch as T\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hid1 = T.nn.Linear(4, 2)  # 6-(10-10)-3\n",
    "        self.oupt = T.nn.Linear(2, 4)\n",
    "    \n",
    "\n",
    "        T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "        T.nn.init.zeros_(self.hid1.bias)\n",
    "        T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "        T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = T.tanh(self.hid1(x))\n",
    "        z = self.oupt(z)  # no softmax: CrossEntropyLoss() \n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aaccf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b48cf064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hid1): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (oupt): Linear(in_features=2, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model:\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ecee0a",
   "metadata": {},
   "source": [
    "## Initializing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f8ea420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net[0] has accesss to the first layer of net\n",
    "\n",
    "# net[0].weight.data.normal_(0, 0.01)\n",
    "# net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de58aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b74164e",
   "metadata": {},
   "source": [
    "## Defining the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44434b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defee6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5142, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing loss function:\n",
    "X = torch.tensor([[-1.2373,  0.3100, -1.4755, -1.1790]])\n",
    "y = X\n",
    "# net(X)\n",
    "loss(net(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a0bd5",
   "metadata": {},
   "source": [
    "## Defining the Optimization Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "727b6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatch stochastic gradient descent is a standard tool for optimizing neural networks and thus\n",
    "# PyTorch supports it alongside a number of variations on this algorithm in the optim module. When\n",
    "# we instantiate an SGD instance, we will specify the parameters to optimize over (obtainable from\n",
    "# our net via net.parameters()), with a dictionary of hyperparameters required by our optimization\n",
    "# algorithm. Minibatch stochastic gradient descent just requires that we set the value lr, which is\n",
    "# set to 0.03 here.\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75d6ba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f5591528c80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d1dccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2037,  0.3724, -0.4606,  0.8351],\n",
       "         [ 0.4188,  0.3827, -0.6066,  0.2799]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.5064, -0.4418],\n",
       "         [ 0.9196, -0.7782],\n",
       "         [-0.8896, -0.2414],\n",
       "         [ 0.1819, -0.0038]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1cc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c932f078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.185904\n",
      "epoch 11, loss 0.007006\n",
      "epoch 21, loss 0.003356\n",
      "epoch 31, loss 0.001762\n",
      "epoch 41, loss 0.001240\n",
      "epoch 51, loss 0.001158\n",
      "epoch 61, loss 0.001083\n",
      "epoch 71, loss 0.001411\n",
      "epoch 81, loss 0.001136\n",
      "epoch 91, loss 0.000847\n",
      "epoch 101, loss 0.000693\n",
      "epoch 111, loss 0.000642\n",
      "epoch 121, loss 0.000652\n",
      "epoch 131, loss 0.000611\n",
      "epoch 141, loss 0.000653\n",
      "epoch 151, loss 0.000547\n",
      "epoch 161, loss 0.001121\n",
      "epoch 171, loss 0.000507\n",
      "epoch 181, loss 0.000512\n",
      "epoch 191, loss 0.000494\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    for X,Y in data_iter:\n",
    "#         print(X,Y)\n",
    "        l = loss(net(X), Y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step() #optimizer\n",
    "    l = loss(net(features), labels)\n",
    "#     print(net[0].weight.data)\n",
    "    if (epoch%10 == 0):\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44d8b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2258f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99547f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08290fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98421b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc8dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7a85921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0996, 0.1989, 0.3279, 0.4004], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how our model represent a data sample like this: [0.1, 0.2, 0.3, 0.4]\n",
    "x = torch.tensor([0.1, 0.2, 0.3, 0.4])\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefe94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39c1c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was just a simple example with linear relationship between colmns. \n",
    "# How about more complex relationships?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9737a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce73a8-4164-4101-91e9-cdc65b505c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
